version: "3.5"

services:
  etcd:
    container_name: milvus-etcd
    image: quay.io/coreos/etcd:v3.5.25
    environment:
      - ETCD_AUTO_COMPACTION_MODE=revision
      - ETCD_AUTO_COMPACTION_RETENTION=1000
      - ETCD_QUOTA_BACKEND_BYTES=4294967296
      - ETCD_SNAPSHOT_COUNT=50000
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/etcd:/etcd
    command: >
      etcd
      -advertise-client-urls=http://etcd:2379
      -listen-client-urls http://0.0.0.0:2379
      --data-dir /etcd
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 30s
      timeout: 20s
      retries: 3

  minio:
    container_name: milvus-minio
    image: minio/minio:RELEASE.2024-12-18T13-15-44Z
    environment:
      MINIO_ACCESS_KEY: minioadmin
      MINIO_SECRET_KEY: minioadmin
    ports:
      - "9001:9001"
      - "9000:9000"
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/minio:/minio_data
    command: minio server /minio_data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  standalone:
    container_name: milvus-standalone
    image: milvusdb/milvus:v2.6.7
    command: ["milvus", "run", "standalone"]
    security_opt:
      - seccomp:unconfined
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio:9000
      MQ_TYPE: woodpecker
    volumes:
      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/milvus:/var/lib/milvus
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/healthz"]
      interval: 30s
      start_period: 90s
      timeout: 20s
      retries: 3
    ports:
      - "19530:19530"
      - "9091:9091"
    depends_on:
      - etcd
      - minio

  embed-api:
    container_name: embed-api
    build:
      context: ./services/embed-api
    environment:
      MILVUS_HOST: standalone
      MILVUS_PORT: "19530"
      MILVUS_COLLECTION: ${MILVUS_COLLECTION:-kure_docs}
      EMBED_MODEL: ${EMBED_MODEL:-nlpai-lab/KURE-v1}
      HF_HOME: /cache/hf
    volumes:
      - hf_cache:/cache/hf
    ports:
      - "8000:8000"
    depends_on:
      - standalone
    restart: unless-stopped

  ollama:
    container_name: ollama
    image: ollama/ollama:latest
    environment:
      OLLAMA_HOST: 0.0.0.0:11434
    ports:
      - "11434:11434"
    volumes:
      - ollama:/root/.ollama
    gpus: all
    restart: unless-stopped

  llm:
    container_name: llm
    build:
      context: ./services/llm
    environment:
      EMBED_API_URL: http://embed-api:8000
      OLLAMA_URL: http://ollama:11434
      OLLAMA_MODEL: gpt-oss:20b
      # 옵션(원하면)
      NUM_PREDICT: "256"
      NUM_CTX: "4096"
      TEMPERATURE: "0.2"
    ports:
      - "8010:8010"
    depends_on:
      - embed-api
      - ollama
    restart: unless-stopped

  web:
    container_name: web
    build:
      context: ./services/web
    environment:
      # Next 서버가 컨테이너 내부에서 호출할 주소(도커 네트워크)
      EMBED_API_URL: http://embed-api:8000
      LLM_API_URL: http://llm:8010
    ports:
      - "3000:3000"
    depends_on:
      - embed-api
      - llm
    restart: unless-stopped

networks:
  default:
    name: milvus

volumes:
  hf_cache:
  # ✅ 추가: Ollama 모델 캐시 볼륨
  ollama:
